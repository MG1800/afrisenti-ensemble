{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-02-07T11:44:54.161129Z","iopub.execute_input":"2023-02-07T11:44:54.161521Z","iopub.status.idle":"2023-02-07T11:45:04.993795Z","shell.execute_reply.started":"2023-02-07T11:44:54.161486Z","shell.execute_reply":"2023-02-07T11:45:04.992523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-02-07T11:45:04.996720Z","iopub.execute_input":"2023-02-07T11:45:04.997163Z","iopub.status.idle":"2023-02-07T11:45:05.003239Z","shell.execute_reply.started":"2023-02-07T11:45:04.997117Z","shell.execute_reply":"2023-02-07T11:45:05.002028Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:05.005044Z","iopub.execute_input":"2023-02-07T11:45:05.005590Z","iopub.status.idle":"2023-02-07T11:45:06.089655Z","shell.execute_reply.started":"2023-02-07T11:45:05.005554Z","shell.execute_reply":"2023-02-07T11:45:06.088497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cd /kaggle/working\n\n# !mkdir -p /kaggle/working/formatted_data/train\n\n# !mkdir -p /kaggle/working/formatted_data/dev\n# !mkdir -p /kaggle/working/formatted_data/test\n\n# !ls /kaggle/working/formatted_data\n# !rm -rf /kaggle/working/outputs\n# !mkdir -p /kaggle/working/outputs\n\n# !ls /kaggle/working/formatted_data/test\n# !mv /kaggle/working/formatted_data/test/*_dev.tsv /kaggle/working/formatted_data/dev/ \n# !ls /kaggle/working/formatted_data/dev\n# !ls /kaggle/working/formatted_data/test","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.093207Z","iopub.execute_input":"2023-02-07T11:45:06.093624Z","iopub.status.idle":"2023-02-07T11:45:06.098412Z","shell.execute_reply.started":"2023-02-07T11:45:06.093588Z","shell.execute_reply":"2023-02-07T11:45:06.097376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splits = ['train', 'dev']\n# languages = ['am', 'dz', 'ha', 'ig', 'ma', 'pcm', 'pt', 'sw', 'yo', 'twi', 'kr', 'ts', 'multilingual']\n\n# for lang in languages:\n#     for split in splits:\n#         df = pd.read_csv(f\"{INPUT_DIR}/{split}/{lang}_{split}.tsv\", sep='\\t')\n               \n#         df = df.drop(['ID'], axis = 1)\n#         df.rename(columns={'tweet':'text', 'label':'labels'}, inplace=True)\n# #         df.sample(5)\n#         df.to_csv(f\"{DATA_DIR}/{split}/{lang}_{split}.tsv\", sep='\\t', index=False)\n\n# # !ls /kaggle/working/formatted_data/*\n# df.sample(5)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-02-07T11:45:06.100150Z","iopub.execute_input":"2023-02-07T11:45:06.101520Z","iopub.status.idle":"2023-02-07T11:45:06.109989Z","shell.execute_reply.started":"2023-02-07T11:45:06.101479Z","shell.execute_reply":"2023-02-07T11:45:06.109042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp /kaggle/input/semevalafrisenti/comb_data/test/* /kaggle/working/formatted_data/test/\n# !cp /kaggle/input/semevalafrisenti/comb_data/dev/* /kaggle/working/formatted_data/test/\n\n# languages = ['_am_', 'dz', '_ha_', '_ig_', '_ma_', '_pcm_', 'pt', 'sw', '_yo_', '_twi', 'kr', 'ts', 'multilingual']\n\n# kr_, _pt, _sw, dz, tshaa\n\nlang = 'ts'\n\n\nTRIAL = False\nCLEAN = False\nDEMOJI = False\n\n\nDATA_DIR = '/kaggle/input/semevalafrisenti/comb_data'\n\nWORKING_DIR = \"/kaggle/temp/working_dir\"\n\n\n\n\nif not os.path.exists(WORKING_DIR):\n    os.makedirs(WORKING_DIR)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.112023Z","iopub.execute_input":"2023-02-07T11:45:06.112978Z","iopub.status.idle":"2023-02-07T11:45:06.125786Z","shell.execute_reply.started":"2023-02-07T11:45:06.112942Z","shell.execute_reply":"2023-02-07T11:45:06.124844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel, ClassificationArgs\nimport pandas as pd\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.127316Z","iopub.execute_input":"2023-02-07T11:45:06.127950Z","iopub.status.idle":"2023-02-07T11:45:06.138275Z","shell.execute_reply.started":"2023-02-07T11:45:06.127914Z","shell.execute_reply":"2023-02-07T11:45:06.137301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport emoji\n\ndef cleaner(tweet):\n    whitespace = re.compile(r\"\\s+\")\n    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n    \n#     tweet = text.replace(\"@user\", \"\")\n    tweet = whitespace.sub(' ', tweet)\n    tweet = web_address.sub('', tweet)\n    tweet = user.sub('', tweet)\n    return tweet","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.139867Z","iopub.execute_input":"2023-02-07T11:45:06.140347Z","iopub.status.idle":"2023-02-07T11:45:06.149116Z","shell.execute_reply.started":"2023-02-07T11:45:06.140303Z","shell.execute_reply":"2023-02-07T11:45:06.148216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{DATA_DIR}/train/{lang}_train.tsv\", sep = '\\t')\n\ntrain_df = train_df.drop(columns=['ID'])\ntrain_df = train_df.rename(columns = {'tweet':'text', 'label':'labels'})\n\nif TRIAL:\n    train_df = train_df.sample(1000)\n\ntrain_df[\"labels\"] = [{\n    'negative':0,\n    'neutral':1,\n    'positive':2,\n}[v] for v in train_df[\"labels\"]]\n\nif DEMOJI:\n    train_df['text'] = train_df['text'].apply(lambda x: emoji.demojize(x, delimiters=(\"\", \"\")))    \nif CLEAN:\n    train_df['text'] = train_df['text'].apply(lambda x: cleaner(x))\n\n\ntrain_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.151729Z","iopub.execute_input":"2023-02-07T11:45:06.152013Z","iopub.status.idle":"2023-02-07T11:45:06.192989Z","shell.execute_reply.started":"2023-02-07T11:45:06.151989Z","shell.execute_reply":"2023-02-07T11:45:06.192107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_args = ClassificationArgs()\nmodel_args.num_train_epochs = 5\n\nif TRIAL:\n    model_args.num_train_epochs = 1\n# model_args.labels_list = [\"positive\", \"negative\", \"neutral\"]\nmodel_args.save_steps = -1\nmodel_args.output_dir = WORKING_DIR\nmodel_args.train_batch_size = 8\nmodel_args.overwrite_output_dir = True\n# model_args.best_model_dir = f\"{OUTPUT_DIR}/best_model\"\n","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.196191Z","iopub.execute_input":"2023-02-07T11:45:06.196504Z","iopub.status.idle":"2023-02-07T11:45:06.201926Z","shell.execute_reply.started":"2023-02-07T11:45:06.196472Z","shell.execute_reply":"2023-02-07T11:45:06.200980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n\ndef get_scores(split, dev_true, dev_pred):\n    print(len(dev_true), len(dev_pred))\n    \n    with open(f\"{OUTPUT_DIR}/{lang}_{split}_scores.txt\", 'w') as output_file:\n        if split == 'dev':\n            print(MODEL)\n            print(classification_report(dev_true, dev_pred))\n        output_file.write(classification_report(dev_true, dev_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.203302Z","iopub.execute_input":"2023-02-07T11:45:06.204044Z","iopub.status.idle":"2023-02-07T11:45:06.211902Z","shell.execute_reply.started":"2023-02-07T11:45:06.204009Z","shell.execute_reply":"2023-02-07T11:45:06.210943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# MODEL_LIST = ['afroxlmr', 'naijasenti', 'afriberta', 'xlmr', 'mbert']\n\nMODEL_LIST = ['afroxlmr']\n\nfor MODEL in MODEL_LIST:\n    \n\n    VARIANT = \"\"\n    # DATA_DIR = '/kaggle/working/formatted_data'\n    OUTPUT_DIR = f\"/kaggle/working/post_exp/{MODEL}{VARIANT}\"\n    \n    if not os.path.exists(OUTPUT_DIR):\n        os.makedirs(OUTPUT_DIR)\n    \n    \n    if MODEL == 'afroxlmr':\n        print(\"AFRO-XLMR\")\n        model = ClassificationModel(\n            'xlmroberta', 'Davlan/afro-xlmr-base', args=model_args, num_labels=3\n        )\n    elif MODEL == 'naijasenti':\n        print('NAIJASENTI')\n        model = ClassificationModel(\n            'xlmroberta', 'Davlan/naija-twitter-sentiment-afriberta-large', args=model_args, num_labels=3\n        )\n    elif MODEL == 'afriberta':\n        print('AFRIBERTA')\n        model = ClassificationModel(\n            'xlmroberta', 'castorini/afriberta_base', args=model_args, num_labels=3\n        )\n    elif MODEL == 'xlmr':\n        print('XLM-RoBERTa')\n        model = ClassificationModel(\n            'xlmroberta', 'xlm-roberta-base', args=model_args, num_labels=3\n        )\n    elif MODEL == 'mbert':\n        print('MBERT')\n        model = ClassificationModel(\n            'bert', 'bert-base-multilingual-cased', args=model_args, num_labels=3\n        )\n\n    model.train_model(train_df)\n\n    splits = ['train', 'dev', 'test']\n\n    for split in splits:\n        df = pd.read_csv(f\"{DATA_DIR}/{split}/{lang}_{split}.tsv\", sep = '\\t')\n\n        if TRIAL:\n            df = df.sample(100)\n\n        if split == 'train':\n            df.rename(columns = {'text':'tweet', 'labels':'label'}, inplace=True)\n        if DEMOJI:\n            df['tweet'] = df['tweet'].apply(lambda x: emoji.demojize(x, delimiters=(\"\", \"\")))    \n        if CLEAN:\n            df['tweet'] = df['tweet'].apply(lambda x: cleaner(x))\n\n        pred, outputs = model.predict(list(df['tweet']))\n        df['pred'] = pred\n        df[\"pred\"] = [{\n            0:'negative',\n            1:'neutral',\n            2:'positive',\n        }[v] for v in df[\"pred\"]]\n\n        if split != 'test':\n            get_scores(split, list(df['label']), list(df['pred']))\n\n        neg, neut, pos = [], [], []\n\n        for output in outputs:\n            neg.append(output[0])\n            neut.append(output[1])\n            pos.append(output[2])\n\n        df['negative'] = neg\n        df['neutral'] = neut\n        df['positive'] = pos\n\n\n        df.to_csv(f\"{OUTPUT_DIR}/{lang}_{split}_output.tsv\", sep='\\t', index=False)\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:45:06.213505Z","iopub.execute_input":"2023-02-07T11:45:06.214189Z","iopub.status.idle":"2023-02-07T11:51:09.955502Z","shell.execute_reply.started":"2023-02-07T11:45:06.214154Z","shell.execute_reply":"2023-02-07T11:51:09.954524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls fu\n","metadata":{"execution":{"iopub.status.busy":"2023-02-17T02:35:33.573046Z","iopub.execute_input":"2023-02-17T02:35:33.573565Z","iopub.status.idle":"2023-02-17T02:35:34.678682Z","shell.execute_reply.started":"2023-02-17T02:35:33.573522Z","shell.execute_reply":"2023-02-17T02:35:34.676902Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"afriberta  afroxlmr  naijasenti\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat full_outputs/afriberta/ig_dev_scores.txt","metadata":{"execution":{"iopub.status.busy":"2023-02-17T02:42:50.539738Z","iopub.execute_input":"2023-02-17T02:42:50.540315Z","iopub.status.idle":"2023-02-17T02:42:51.679813Z","shell.execute_reply.started":"2023-02-17T02:42:50.540265Z","shell.execute_reply":"2023-02-17T02:42:51.678586Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"WEIGHTED F1\n\navg_precision:0.8033168738841202\navg_recall:0.8033677349266702\navg_f1_score:0.8033410742846602\n\nMACRO F1\n\nmacro_precision:0.8025792478125137\nmacro_recall:0.8023123509445229\nmacro_f1_score:0.8024443091259535\n","output_type":"stream"}]},{"cell_type":"code","source":"# !cat outputs/afriberta_er/train_scores.txt\n# !ls outputs/afriberta","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:51:11.021845Z","iopub.execute_input":"2023-02-07T11:51:11.022536Z","iopub.status.idle":"2023-02-07T11:51:11.027274Z","shell.execute_reply.started":"2023-02-07T11:51:11.022490Z","shell.execute_reply":"2023-02-07T11:51:11.026300Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# df = pd.read_csv('outputs/afriberta/ha_train_output.tsv', sep = '\\t')\n# df","metadata":{"execution":{"iopub.status.busy":"2023-02-07T11:51:11.028793Z","iopub.execute_input":"2023-02-07T11:51:11.029408Z","iopub.status.idle":"2023-02-07T11:51:11.037561Z","shell.execute_reply.started":"2023-02-07T11:51:11.029372Z","shell.execute_reply":"2023-02-07T11:51:11.036644Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}